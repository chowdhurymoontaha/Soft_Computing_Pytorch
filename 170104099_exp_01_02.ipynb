{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "170104099_exp_01_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d502e7eb6ca4069bd27062b74b331dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dfa9928cc22244deb2bc9fb49d4e987e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49e1b143c3a54265993acf8ab3d18410",
              "IPY_MODEL_38f0e88647e942d79e30f60eef63fb58",
              "IPY_MODEL_8c696c736ff6403f8fdea2651ba92237"
            ]
          }
        },
        "dfa9928cc22244deb2bc9fb49d4e987e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49e1b143c3a54265993acf8ab3d18410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13a0b2f2c4284b198736384021a22fdf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f32fd84fbb0e4bce922ff7261546e490"
          }
        },
        "38f0e88647e942d79e30f60eef63fb58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bfe9836ef4d491fa3096c993f716199",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d66e923a1794fe7bc980471e7693531"
          }
        },
        "8c696c736ff6403f8fdea2651ba92237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d9ae84da2d80461ca310e9974159a45c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 23823779.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e26f8f9127314038a10e9a179692f678"
          }
        },
        "13a0b2f2c4284b198736384021a22fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f32fd84fbb0e4bce922ff7261546e490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bfe9836ef4d491fa3096c993f716199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d66e923a1794fe7bc980471e7693531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9ae84da2d80461ca310e9974159a45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e26f8f9127314038a10e9a179692f678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47844d3b80644b2dae20e2010948a5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2925d88ecc54d79a1024ee5082b1649",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f58ac42abdb246ac8c0d67ef98433e35",
              "IPY_MODEL_3cdb21f4ec3a4474943ed4e0f41c1718",
              "IPY_MODEL_a1d08a47af1342928d5da6de3779b3bc"
            ]
          }
        },
        "f2925d88ecc54d79a1024ee5082b1649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f58ac42abdb246ac8c0d67ef98433e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f9fac10911141e5a4ad95087975a8f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3eff9abe11fd49719a494c0878f2aeeb"
          }
        },
        "3cdb21f4ec3a4474943ed4e0f41c1718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_66cd0ae1c693464b834b4d3e1bdaf515",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54d7cfc7d3d446fcadc1ff3a31c88d4c"
          }
        },
        "a1d08a47af1342928d5da6de3779b3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c835b5ebef03480dbea0c8520cc4fc1b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 577186.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c211dff27db34d01b56a507d984e5e4e"
          }
        },
        "5f9fac10911141e5a4ad95087975a8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3eff9abe11fd49719a494c0878f2aeeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66cd0ae1c693464b834b4d3e1bdaf515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54d7cfc7d3d446fcadc1ff3a31c88d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c835b5ebef03480dbea0c8520cc4fc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c211dff27db34d01b56a507d984e5e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b86a8364470d4139a49a32b34b4dd286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a352e8542a74b73b6d024aba70d2550",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2699895199541d6a749d2f2afaf6840",
              "IPY_MODEL_f52bde03a1c4472eb724fb0e4953fde4",
              "IPY_MODEL_cfe7dfee2f6c41e99c70ad483c2a56d2"
            ]
          }
        },
        "3a352e8542a74b73b6d024aba70d2550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2699895199541d6a749d2f2afaf6840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f81e1a25078a4be29a0203344bcb8528",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cba37857a632416eb6050ceea00bb3cc"
          }
        },
        "f52bde03a1c4472eb724fb0e4953fde4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1288fddb9d804efd88ff40de012574e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cbb9c2e7a0040aabc1a116bbf3d5e06"
          }
        },
        "cfe7dfee2f6c41e99c70ad483c2a56d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b76d89644ae40cbbd98aff08230ec3b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 4338069.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc8233d5e7124c64a3cd58cf7515292e"
          }
        },
        "f81e1a25078a4be29a0203344bcb8528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cba37857a632416eb6050ceea00bb3cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1288fddb9d804efd88ff40de012574e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cbb9c2e7a0040aabc1a116bbf3d5e06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b76d89644ae40cbbd98aff08230ec3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc8233d5e7124c64a3cd58cf7515292e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f214691a272e4ab68ffe129e790c2f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd09e4d94079481484e65c451c25c76a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8aa66404af5647f4a3687e831ee5956e",
              "IPY_MODEL_967420326e954ecab44016beb8f824e7",
              "IPY_MODEL_893c8d81c5b9420eb82cc964bc474fed"
            ]
          }
        },
        "cd09e4d94079481484e65c451c25c76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8aa66404af5647f4a3687e831ee5956e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab57363afa2f47e38a51d43256fe5406",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_380e25e9c60e4788be7730704bb8b3d0"
          }
        },
        "967420326e954ecab44016beb8f824e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_234faa2d11c240cba498dd9adc56dc24",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e65fff091a04d4bb1badb0a08b55114"
          }
        },
        "893c8d81c5b9420eb82cc964bc474fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5cc753dbee744fa389353fc71e8e2a44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 99796.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4ae763339cf4a05bbbb47fc920674cd"
          }
        },
        "ab57363afa2f47e38a51d43256fe5406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "380e25e9c60e4788be7730704bb8b3d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "234faa2d11c240cba498dd9adc56dc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e65fff091a04d4bb1badb0a08b55114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cc753dbee744fa389353fc71e8e2a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4ae763339cf4a05bbbb47fc920674cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chowdhurymoontaha/soft_ComputerLab/blob/main/170104099_exp_01_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxN-N3KYOOKh",
        "outputId": "b599fd45-2d0a-4534-9f62-38080c3492ac"
      },
      "source": [
        "  from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKeqS0ypOfR2"
      },
      "source": [
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkVe3IREepmg"
      },
      "source": [
        "!unzip -uq \"/content/gdrive/MyDrive/Colab Notebooks/softCompAssignment2/Dataset C.zip\" -d \"/content/gdrive/MyDrive/Colab Notebooks/softCompAssignment2/DatasetC\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "2-Phf0UHf2-9",
        "outputId": "1a61b103-e038-446c-b353-6383c029b71d"
      },
      "source": [
        "df_c_csv=pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/softCompAssignment2/DatasetC/training-c.csv\")\n",
        "df_c_csv.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>original filename</th>\n",
              "      <th>scanid</th>\n",
              "      <th>digit</th>\n",
              "      <th>database name original</th>\n",
              "      <th>contributing team</th>\n",
              "      <th>database name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c00000.png</td>\n",
              "      <td>Scan_280_digit_6_num_7.png</td>\n",
              "      <td>280</td>\n",
              "      <td>6</td>\n",
              "      <td>OngkoDB</td>\n",
              "      <td>Buet_Backpropers</td>\n",
              "      <td>training-c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c00001.png</td>\n",
              "      <td>Scan_29_digit_1_num_1.png</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>OngkoDB</td>\n",
              "      <td>Buet_Backpropers</td>\n",
              "      <td>training-c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c00002.png</td>\n",
              "      <td>Scan_131_digit_3_num_1.png</td>\n",
              "      <td>131</td>\n",
              "      <td>3</td>\n",
              "      <td>OngkoDB</td>\n",
              "      <td>Buet_Backpropers</td>\n",
              "      <td>training-c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c00003.png</td>\n",
              "      <td>Scan_160_digit_2_num_2.png</td>\n",
              "      <td>160</td>\n",
              "      <td>2</td>\n",
              "      <td>OngkoDB</td>\n",
              "      <td>Buet_Backpropers</td>\n",
              "      <td>training-c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c00004.png</td>\n",
              "      <td>Scan_202_digit_7_num_0.png</td>\n",
              "      <td>202</td>\n",
              "      <td>7</td>\n",
              "      <td>OngkoDB</td>\n",
              "      <td>Buet_Backpropers</td>\n",
              "      <td>training-c</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     filename           original filename  ...  contributing team  database name\n",
              "0  c00000.png  Scan_280_digit_6_num_7.png  ...   Buet_Backpropers     training-c\n",
              "1  c00001.png   Scan_29_digit_1_num_1.png  ...   Buet_Backpropers     training-c\n",
              "2  c00002.png  Scan_131_digit_3_num_1.png  ...   Buet_Backpropers     training-c\n",
              "3  c00003.png  Scan_160_digit_2_num_2.png  ...   Buet_Backpropers     training-c\n",
              "4  c00004.png  Scan_202_digit_7_num_0.png  ...   Buet_Backpropers     training-c\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "OcMK_V-QhHMM",
        "outputId": "80a10a93-43f5-47f1-dccb-40b9b2fc1580"
      },
      "source": [
        "df_c_csv =df_c_csv.drop(columns=['original filename', 'scanid',\n",
        "       'database name original', 'contributing team', 'database name'])\n",
        "df_c_csv.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c00000.png</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c00001.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c00002.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c00003.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c00004.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     filename  digit\n",
              "0  c00000.png      6\n",
              "1  c00001.png      1\n",
              "2  c00002.png      3\n",
              "3  c00003.png      2\n",
              "4  c00004.png      7"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYC_GzybhWn4",
        "outputId": "f8badc39-7402-45c0-c004-87e058fea2d6"
      },
      "source": [
        "df_c_csv.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24298, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3i_LyjtpTsx",
        "outputId": "078cb0ee-b06a-4023-b8a5-56aa288d80c1"
      },
      "source": [
        "PATH = \"/content/gdrive/MyDrive/Colab Notebooks/softCompAssignment2/DatasetC\"\n",
        "os.listdir(PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['training-c', 'training-c.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "DRR7u9LJqxCl",
        "outputId": "639c17d5-d6d7-4be7-ead8-ae89c43e1f2f"
      },
      "source": [
        "from PIL import Image\n",
        "data_dir = '/content/gdrive/MyDrive/Colab Notebooks/softCompAssignment2/DatasetC/training-c'\n",
        "name = os.listdir(data_dir)[10]\n",
        "Image.open(data_dir+\"/\"+name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=180x180 at 0x7F30942E67D0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le-uSYzeo4W9"
      },
      "source": [
        "TRAIN_PATH =  '/content/gdrive/MyDrive/Colab Notebooks/softCompAssignment2/DatasetC/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTqwSz48pIG-"
      },
      "source": [
        "#making folder train\n",
        "os.mkdir(TRAIN_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2nAKklxsyXN"
      },
      "source": [
        "#import shutil\n",
        "#import os\n",
        "\n",
        "os.chdir('/content/gdrive/MyDrive/Colab Notebooks/softCompAssignment2/DatasetC/training-c')\n",
        "dst_dir = '/content/gdrive/MyDrive/Colab Notebooks/softCompAssignment2/DatasetC/train'\n",
        "for f in os.listdir():\n",
        "    shutil.copy(f, dst_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b10-Kh-nh9ET"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, df, root, transform=None):\n",
        "        self.data = df\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.data.iloc[index]\n",
        "        \n",
        "        path = self.root + \"/\" + item[0]\n",
        "        image = Image.open(path).convert('L')\n",
        "        label = item[1]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_xoJlxWiNWh",
        "outputId": "f6baf93a-6d20-4746-f954-d73573285c0d"
      },
      "source": [
        "# Normalizing data\n",
        "mean = [0.5,]\n",
        "std = [0.5, ]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(180),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(180),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_data  = Dataset(df_c_csv, TRAIN_PATH, train_transform)\n",
        "test_data = Dataset(df_c_csv,TRAIN_PATH, test_transform)\n",
        "\n",
        "print(\"Trainig Samples: \",len(train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainig Samples:  24298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsamOQpXi8SY"
      },
      "source": [
        "#Experiment-1\n",
        "#Combination-1:\n",
        "iteration=20000, epoch=16, lr=0.01, batch size=20, optimizer=Adam, num_hidden = 200, Layer=6, activations=ReLU, Loss function=CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK9L7sfii2DP"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 20\n",
        "num_iters = 20000\n",
        "num_hidden = 200\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHqHwwcjlZxP",
        "outputId": "3f70aa6c-81fc-4990-e800-996a7b9c5d88"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpOms0raldBe",
        "outputId": "364fac6b-2dbc-44d3-c4ee-67c1410354c0"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 20\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataloader:972\n",
            "Test dataloader:243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaZj9I7Sl44O"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.ReLU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.ReLU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.ReLU()\n",
        "\n",
        "        \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.ReLU()\n",
        "\n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsGRhoebmXHJ",
        "outputId": "e9c2df0b-0f5a-4d0d-e4cf-ea319aa0a3b5"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): ReLU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): ReLU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): ReLU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): ReLU()\n",
              "  (linear_5): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_5): ReLU()\n",
              "  (linear_6): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_6): ReLU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR6G9SpKmbTr"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6VY2zr0moi4",
        "outputId": "8e99a016-ccdc-4ae9-861d-f01ffa4df877"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 1000 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "Iteration: 1000. Loss: 2.3164916038513184. Accuracy: 10.351924264251904\n",
            "2\n",
            "Iteration: 2000. Loss: 2.3116366863250732. Accuracy: 9.220004116073266\n",
            "3\n",
            "Iteration: 3000. Loss: 2.284975528717041. Accuracy: 9.878575838649928\n",
            "4\n",
            "Iteration: 4000. Loss: 2.295339345932007. Accuracy: 9.508129244700555\n",
            "5\n",
            "Iteration: 5000. Loss: 2.304908275604248. Accuracy: 9.878575838649928\n",
            "6\n",
            "Iteration: 6000. Loss: 2.303511142730713. Accuracy: 10.166700967277217\n",
            "7\n",
            "Iteration: 7000. Loss: 2.310652494430542. Accuracy: 10.804692323523359\n",
            "8\n",
            "Iteration: 8000. Loss: 2.3198015689849854. Accuracy: 9.878575838649928\n",
            "9\n",
            "Iteration: 9000. Loss: 2.301771879196167. Accuracy: 9.816834739658367\n",
            "10\n",
            "Iteration: 10000. Loss: 2.302553415298462. Accuracy: 10.351924264251904\n",
            "11\n",
            "Iteration: 11000. Loss: 2.3003268241882324. Accuracy: 9.220004116073266\n",
            "12\n",
            "Iteration: 12000. Loss: 2.3001599311828613. Accuracy: 10.351924264251904\n",
            "13\n",
            "Iteration: 13000. Loss: 2.3036296367645264. Accuracy: 9.220004116073266\n",
            "14\n",
            "Iteration: 14000. Loss: 2.3117780685424805. Accuracy: 9.220004116073266\n",
            "15\n",
            "Iteration: 15000. Loss: 2.30698823928833. Accuracy: 9.508129244700555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irkwsiXfjcJK"
      },
      "source": [
        "comb1={'Loss':[2.3164916038513184,2.3116366863250732,2.284975528717041,2.295339345932007,2.304908275604248,2.303511142730713,\n",
        "               2.310652494430542,2.3198015689849854,2.301771879196167,2.302553415298462,2.3003268241882324,2.3001599311828613,\n",
        "               2.3036296367645264,2.3117780685424805,2.30698823928833], \n",
        "       'Accuracy':[10.351924264251904,9.220004116073266,9.878575838649928,9.508129244700555,9.878575838649928,10.166700967277217,\n",
        "                   10.804692323523359,9.878575838649928,9.816834739658367,10.351924264251904,9.220004116073266,10.351924264251904,\n",
        "                   9.220004116073266,9.220004116073266,9.508129244700555],\n",
        "       'Iteration':[1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000]}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pUG4g8JVl37K",
        "outputId": "c8f6f819-1958-4ba1-98a2-15b30f2e0383"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(comb1['Accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7wRdmCIlm3r_",
        "outputId": "a54d22b4-aa50-463a-97f7-00d9af1a439c"
      },
      "source": [
        "plt.plot(comb1['Iteration'],comb1['Loss'])\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em2potPhGr5y"
      },
      "source": [
        "# Expeiment-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNxa8hoLthYo"
      },
      "source": [
        "# Combination-2:\n",
        "iteration=20000, epoch=82, lr=0.01, batch size=100, optimizer=Adam, num_hidden = 200, Layer=6, activations=ReLU, Loss function=CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwVAX8jqtlwK"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 100\n",
        "num_iters = 20000\n",
        "num_hidden = 200\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7nr-W3Ttr13",
        "outputId": "b52e7a20-009c-4700-fe06-988e201b5ca8"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2x4co18twmx",
        "outputId": "088d8755-5572-40af-e6eb-3c945cb46ac6"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 100\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataloader:195\n",
            "Test dataloader:49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3pB9cdkt3uD"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.ReLU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.ReLU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.ReLU()\n",
        "\n",
        "        \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.ReLU()\n",
        "\n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpc7Wp2VuD0r",
        "outputId": "55861fb5-8c19-4165-e635-a198c67c1b13"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): ReLU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): ReLU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): ReLU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): ReLU()\n",
              "  (linear_5): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_5): ReLU()\n",
              "  (linear_6): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_6): ReLU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTD5y57huKH_"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_hPvZzHuOqM",
        "outputId": "d089cb78-dfcd-4645-efe8-c76ef7fda8bc"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 1000 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Iteration: 1000. Loss: 2.30471134185791. Accuracy: 9.199423749742746\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Iteration: 2000. Loss: 2.297900915145874. Accuracy: 9.220004116073266\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "Iteration: 3000. Loss: 2.3025684356689453. Accuracy: 9.220004116073266\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "Iteration: 4000. Loss: 2.2998054027557373. Accuracy: 10.290183165260341\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "Iteration: 5000. Loss: 2.293428659439087. Accuracy: 9.199423749742746\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "Iteration: 6000. Loss: 2.304588556289673. Accuracy: 10.372504630582425\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "Iteration: 7000. Loss: 2.30043363571167. Accuracy: 10.55772792755711\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "Iteration: 8000. Loss: 2.3046042919158936. Accuracy: 9.919736571310969\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "Iteration: 9000. Loss: 2.3010454177856445. Accuracy: 10.187281333607737\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "Iteration: 10000. Loss: 2.3039557933807373. Accuracy: 9.199423749742746\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "Iteration: 11000. Loss: 2.3034822940826416. Accuracy: 9.199423749742746\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "Iteration: 12000. Loss: 2.307642698287964. Accuracy: 9.199423749742746\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "Iteration: 13000. Loss: 2.302370071411133. Accuracy: 9.220004116073266\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "Iteration: 14000. Loss: 2.306267023086548. Accuracy: 9.199423749742746\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "Iteration: 15000. Loss: 2.3000242710113525. Accuracy: 9.32290594772587\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQO3h8MlCMJs"
      },
      "source": [
        "# Combination-3: \n",
        "iteration=20000, epoch=16, lr=0.01, batch size=20, optimizer=Adam, num_hidden = 200, Layer=6, activations=SELU(), Loss function=CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8OG5d9kCPjV"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 20\n",
        "num_iters = 20000\n",
        "num_hidden = 200\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnyxrcCPCPzS",
        "outputId": "4168d815-bb87-4f72-a87f-d233c68f16b2"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rVNCe7OCfHj",
        "outputId": "3c8e8647-7004-43db-c588-db63dfaffb07"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 100\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataloader:972\n",
            "Test dataloader:243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzYvwQ3lCgW4"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.SELU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.SELU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.SELU()\n",
        "\n",
        "        \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.SELU()\n",
        "\n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        self.relu_5 = nn.SELU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        self.relu_6 = nn.SELU()\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZphOTeVjCqzg",
        "outputId": "c2041870-c5d0-43d2-8605-a8cc0af390ff"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): SELU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): SELU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): SELU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): SELU()\n",
              "  (linear_5): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_5): SELU()\n",
              "  (linear_6): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_6): SELU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "depR22-sDX6U"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOt494m9DeEV",
        "outputId": "6369a281-73c5-4aa9-eed0-1a9f444e16cc"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 1000 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "Iteration: 1000. Loss: 2.588547945022583. Accuracy: 9.837415105988887\n",
            "2\n",
            "Iteration: 2000. Loss: 2.437319278717041. Accuracy: 9.775674006997324\n",
            "3\n",
            "Iteration: 3000. Loss: 2.8886985778808594. Accuracy: 9.384647046717431\n",
            "4\n",
            "Iteration: 4000. Loss: 3.240769624710083. Accuracy: 9.775674006997324\n",
            "5\n",
            "Iteration: 5000. Loss: 2.4193406105041504. Accuracy: 10.104959868285656\n",
            "6\n",
            "Iteration: 6000. Loss: 2.346825122833252. Accuracy: 9.384647046717431\n",
            "7\n",
            "Iteration: 7000. Loss: 2.6116583347320557. Accuracy: 9.384647046717431\n",
            "8\n",
            "Iteration: 8000. Loss: 2.4415242671966553. Accuracy: 10.104959868285656\n",
            "9\n",
            "Iteration: 9000. Loss: 2.244157075881958. Accuracy: 10.084379501955135\n",
            "10\n",
            "Iteration: 10000. Loss: 2.620990753173828. Accuracy: 10.104959868285656\n",
            "11\n",
            "Iteration: 11000. Loss: 2.4733071327209473. Accuracy: 10.104959868285656\n",
            "12\n",
            "Iteration: 12000. Loss: 2.518975019454956. Accuracy: 9.384647046717431\n",
            "13\n",
            "Iteration: 13000. Loss: 2.409658908843994. Accuracy: 10.084379501955135\n",
            "14\n",
            "Iteration: 14000. Loss: 2.4406371116638184. Accuracy: 10.084379501955135\n",
            "15\n",
            "Iteration: 15000. Loss: 2.5089211463928223. Accuracy: 10.104959868285656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nhm9ouO7rJv"
      },
      "source": [
        "#Combination-4\n",
        "iteration=20000, epoch=82, lr=0.001, batch size=100, optimizer=Adam, num_hidden = 200, Layer=4, activations=SELU, Loss function=CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGxxdXnV8IrC"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 100\n",
        "num_iters = 20000\n",
        "num_hidden = 200\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woXbrKda8TnC",
        "outputId": "0c01230d-1c6c-4317-d75b-2c038484dbee"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXxtG1Yf8YhO",
        "outputId": "fed37f86-c81f-44dc-dc26-085be469feaf"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 20\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:195\n",
            "Test dataloader:49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUWAgWS-8bS5"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.SELU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.SELU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.SELU()\n",
        " \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.SELU()\n",
        "\n",
        "       \n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        #self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        #self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### 7th hidden layer: 200 --> 200\n",
        "        #self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #self.relu_7 = nn.ReLU()\n",
        "\n",
        "        ### 8th hidden layer: 200 --> 200\n",
        "        #self.linear_8 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #self.relu_8 = nn.ReLU()'''\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        #out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        #out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #out = self.relu_6(out)\n",
        "\n",
        "        ### 7th hidden layer\n",
        "        #out  = self.linear_7(out)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #out = self.relu_7(out)\n",
        "\n",
        "        ### 8th hidden layer\n",
        "        #out  = self.linear_8(out)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #out = self.relu_8(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUsq5_aB8jel",
        "outputId": "fca50a6b-e3f6-426f-ccfd-eda4e693f445"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): SELU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): SELU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): SELU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): SELU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAOHoAyU8mzO"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LwYlRZY8q8W",
        "outputId": "3a212e89-1601-42cd-a0ee-ff8d3acdb314"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "Iteration: 500. Loss: 2.1599316596984863. Accuracy: 17.431570281951018\n",
            "3\n",
            "4\n",
            "5\n",
            "Iteration: 1000. Loss: 1.9047693014144897. Accuracy: 32.84626466351101\n",
            "6\n",
            "7\n",
            "Iteration: 1500. Loss: 1.540004014968872. Accuracy: 39.102696027989296\n",
            "8\n",
            "9\n",
            "10\n",
            "Iteration: 2000. Loss: 1.7444919347763062. Accuracy: 38.75282980037045\n",
            "11\n",
            "12\n",
            "Iteration: 2500. Loss: 1.6556702852249146. Accuracy: 46.07944021403581\n",
            "13\n",
            "14\n",
            "15\n",
            "Iteration: 3000. Loss: 1.3507258892059326. Accuracy: 52.9327022020992\n",
            "16\n",
            "17\n",
            "Iteration: 3500. Loss: 1.2784656286239624. Accuracy: 55.83453385470261\n",
            "18\n",
            "19\n",
            "20\n",
            "Iteration: 4000. Loss: 1.2902441024780273. Accuracy: 56.45194484461823\n",
            "21\n",
            "22\n",
            "23\n",
            "Iteration: 4500. Loss: 1.184516191482544. Accuracy: 54.88783700349866\n",
            "24\n",
            "25\n",
            "Iteration: 5000. Loss: 1.032442331314087. Accuracy: 58.798106606297594\n",
            "26\n",
            "27\n",
            "28\n",
            "Iteration: 5500. Loss: 1.044560432434082. Accuracy: 59.436097962543734\n",
            "29\n",
            "30\n",
            "Iteration: 6000. Loss: 0.9440972805023193. Accuracy: 61.20600946696851\n",
            "31\n",
            "32\n",
            "33\n",
            "Iteration: 6500. Loss: 0.879528820514679. Accuracy: 63.86087672360568\n",
            "34\n",
            "35\n",
            "Iteration: 7000. Loss: 0.9792436361312866. Accuracy: 63.1817246346985\n",
            "36\n",
            "37\n",
            "38\n",
            "Iteration: 7500. Loss: 0.7699567675590515. Accuracy: 65.01337723811484\n",
            "39\n",
            "40\n",
            "41\n",
            "Iteration: 8000. Loss: 0.5725045800209045. Accuracy: 66.51574398024285\n",
            "42\n",
            "43\n",
            "Iteration: 8500. Loss: 0.7431215047836304. Accuracy: 65.85717225766619\n",
            "44\n",
            "45\n",
            "46\n",
            "Iteration: 9000. Loss: 0.6941040754318237. Accuracy: 67.15373533648899\n",
            "47\n",
            "48\n",
            "Iteration: 9500. Loss: 0.8178269267082214. Accuracy: 67.97694998970982\n",
            "49\n",
            "50\n",
            "51\n",
            "Iteration: 10000. Loss: 0.5742537975311279. Accuracy: 69.02654867256638\n",
            "52\n",
            "53\n",
            "Iteration: 10500. Loss: 0.7975818514823914. Accuracy: 66.22761885161556\n",
            "54\n",
            "55\n",
            "56\n",
            "Iteration: 11000. Loss: 0.7212266325950623. Accuracy: 68.32681621732867\n",
            "57\n",
            "58\n",
            "Iteration: 11500. Loss: 0.7875674366950989. Accuracy: 67.15373533648899\n",
            "59\n",
            "60\n",
            "61\n",
            "Iteration: 12000. Loss: 0.3973788917064667. Accuracy: 66.92735130685327\n",
            "62\n",
            "63\n",
            "64\n",
            "Iteration: 12500. Loss: 0.4076818525791168. Accuracy: 66.98909240584483\n",
            "65\n",
            "66\n",
            "Iteration: 13000. Loss: 0.4992326498031616. Accuracy: 68.94422720724428\n",
            "67\n",
            "68\n",
            "69\n",
            "Iteration: 13500. Loss: 0.6988852620124817. Accuracy: 67.11257460382795\n",
            "70\n",
            "71\n",
            "Iteration: 14000. Loss: 0.5562959313392639. Accuracy: 68.03869108870138\n",
            "72\n",
            "73\n",
            "74\n",
            "Iteration: 14500. Loss: 0.35055792331695557. Accuracy: 66.8656102078617\n",
            "75\n",
            "76\n",
            "Iteration: 15000. Loss: 0.5846473574638367. Accuracy: 69.33525416752418\n",
            "77\n",
            "78\n",
            "79\n",
            "Iteration: 15500. Loss: 0.5806601047515869. Accuracy: 68.94422720724428\n",
            "80\n",
            "81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCBjG5DDf9T"
      },
      "source": [
        "#Combination 5\n",
        "iteration=5000, epoch=16, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=4, activations=SELU, Loss function=CrossEntropyLoss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiCwLXZgDsRp"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 200\n",
        "num_iters = 5000\n",
        "num_hidden = 200\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J5N88BvD08I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32e833b-a0a5-465f-ece4-73231aea1cdc"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWziKgGwD4Vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1661370b-adba-4726-8120-8d555d3a56c6"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 20\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:98\n",
            "Test dataloader:25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d1a43fWD5Jh"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.SELU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.SELU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.SELU()\n",
        " \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.SELU()\n",
        "\n",
        "       \n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        #self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        #self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### 7th hidden layer: 200 --> 200\n",
        "        #self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #self.relu_7 = nn.ReLU()\n",
        "\n",
        "        ### 8th hidden layer: 200 --> 200\n",
        "        #self.linear_8 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #self.relu_8 = nn.ReLU()'''\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        #out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        #out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #out = self.relu_6(out)\n",
        "\n",
        "        ### 7th hidden layer\n",
        "        #out  = self.linear_7(out)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #out = self.relu_7(out)\n",
        "\n",
        "        ### 8th hidden layer\n",
        "        #out  = self.linear_8(out)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #out = self.relu_8(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q66lm7-hEAtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08481562-6076-47de-ee4b-03c102b973a5"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): SELU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): SELU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): SELU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): SELU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvAUSl1vEETQ"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjGk8zvUEG6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8eaadf3-0fd7-4c09-c78c-73a8dba1242d"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Iteration: 500. Loss: 2.0474181175231934. Accuracy: 32.702202099197365\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Iteration: 1000. Loss: 1.5499151945114136. Accuracy: 46.75859230294299\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "Iteration: 1500. Loss: 1.2342454195022583. Accuracy: 52.500514509158265\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "Iteration: 2000. Loss: 1.2937580347061157. Accuracy: 57.68676682444948\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "Iteration: 2500. Loss: 0.9670025110244751. Accuracy: 61.30891129862111\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "Iteration: 3000. Loss: 0.9058560729026794. Accuracy: 64.39596624819922\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "Iteration: 3500. Loss: 0.7554568648338318. Accuracy: 64.16958221856349\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "Iteration: 4000. Loss: 0.8808007836341858. Accuracy: 72.03128215682239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbFYNlmZ8Ill"
      },
      "source": [
        "# Combination-6 - My Best Model\n",
        "iteration=20000, epoch=82, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=4, activations=SELU, Loss function=CrossEntropyLoss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la8MHlRO8WVI"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 200\n",
        "num_iters = 20000\n",
        "num_hidden = 200\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_HLtH7F8aRj",
        "outputId": "02a8102b-6d72-4690-bae6-7bda05c08b21"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi24jL-K8eaB",
        "outputId": "0791e983-17de-4be2-9866-8b6f5f9a8787"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 20\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:98\n",
            "Test dataloader:25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZCvh6hh8el8"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.SELU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.SELU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.SELU()\n",
        " \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.SELU()\n",
        "\n",
        "       \n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        #self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        #self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### 7th hidden layer: 200 --> 200\n",
        "        #self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #self.relu_7 = nn.ReLU()\n",
        "\n",
        "        ### 8th hidden layer: 200 --> 200\n",
        "        #self.linear_8 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #self.relu_8 = nn.ReLU()'''\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        #out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        #out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #out = self.relu_6(out)\n",
        "\n",
        "        ### 7th hidden layer\n",
        "        #out  = self.linear_7(out)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #out = self.relu_7(out)\n",
        "\n",
        "        ### 8th hidden layer\n",
        "        #out  = self.linear_8(out)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #out = self.relu_8(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIAQULXS8rTw",
        "outputId": "a08d4b08-d98b-4976-bfa6-d84942b05836"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): SELU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): SELU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): SELU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): SELU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyMTSMJu8v_o"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXR4ENdz8z7r",
        "outputId": "8447a186-1a85-4aee-e18b-66d1a3f64a7b"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Iteration: 500. Loss: 2.0695416927337646. Accuracy: 27.14550318995678\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Iteration: 1000. Loss: 1.6994267702102661. Accuracy: 40.64622350277835\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "Iteration: 1500. Loss: 1.4769307374954224. Accuracy: 42.39555464087261\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "Iteration: 2000. Loss: 1.6211177110671997. Accuracy: 54.04404198394732\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "Iteration: 2500. Loss: 1.0237088203430176. Accuracy: 61.617616793578925\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "Iteration: 3000. Loss: 0.9095052480697632. Accuracy: 66.59806544556493\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "Iteration: 3500. Loss: 0.7204372882843018. Accuracy: 71.90779995883926\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "Iteration: 4000. Loss: 0.7206649780273438. Accuracy: 66.45400288125128\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "Iteration: 4500. Loss: 0.5279945731163025. Accuracy: 74.56266721547644\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "Iteration: 5000. Loss: 0.6024489402770996. Accuracy: 68.14159292035399\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "Iteration: 5500. Loss: 0.45019420981407166. Accuracy: 72.21650545379708\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "Iteration: 6000. Loss: 0.36627519130706787. Accuracy: 76.55896274953695\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "Iteration: 6500. Loss: 0.46207675337791443. Accuracy: 74.9331138094258\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "Iteration: 7000. Loss: 0.3987882137298584. Accuracy: 77.46449886807986\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "Iteration: 7500. Loss: 0.3985902667045593. Accuracy: 75.87981066062976\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "Iteration: 8000. Loss: 0.24038708209991455. Accuracy: 76.20909652191808\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "Iteration: 8500. Loss: 0.48368462920188904. Accuracy: 78.51409755093641\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "Iteration: 9000. Loss: 0.1797271966934204. Accuracy: 75.13891747273101\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "Iteration: 9500. Loss: 0.21242855489253998. Accuracy: 78.22597242230911\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "Iteration: 10000. Loss: 0.13791294395923615. Accuracy: 74.3157028195102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "Iteration: 10500. Loss: 0.2664133310317993. Accuracy: 76.35315908623174\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "Iteration: 11000. Loss: 0.3962131440639496. Accuracy: 77.75262399670714\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "Iteration: 11500. Loss: 0.2044796496629715. Accuracy: 74.54208684914592\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "Iteration: 12000. Loss: 0.1470571756362915. Accuracy: 77.42333813541882\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "Iteration: 12500. Loss: 0.26777637004852295. Accuracy: 79.87240172875077\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "Iteration: 13000. Loss: 0.0674719586968422. Accuracy: 78.96686561020786\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "Iteration: 13500. Loss: 0.06763695180416107. Accuracy: 78.74048158057214\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "Iteration: 14000. Loss: 0.2883085012435913. Accuracy: 72.95739864169582\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "Iteration: 14500. Loss: 0.18935605883598328. Accuracy: 75.3241407697057\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "Iteration: 15000. Loss: 0.24027709662914276. Accuracy: 75.9209713932908\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "Iteration: 15500. Loss: 0.09633754938840866. Accuracy: 79.37847293681827\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "Iteration: 16000. Loss: 0.12690798938274384. Accuracy: 77.67030253138506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr214fLZnekg"
      },
      "source": [
        "comb6={'Loss6':[1.6994267702102661,1.6211177110671997,0.9095052480697632,0.7206649780273438,0.6024489402770996,0.36627519130706787,0.3987882137298584,\n",
        "                0.24038708209991455,0.1797271966934204,0.13791294395923615,0.3962131440639496,0.1470571756362915,0.0674719586968422,0.2883085012435913,\n",
        "                0.24027709662914276,0.12690798938274384],\n",
        "       'Iteration6':[1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000,16000]\n",
        "       }"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iJqyM7bLs20x",
        "outputId": "7939c14d-cf3c-492c-8444-b3773f346c0d"
      },
      "source": [
        "plt.plot(comb6['Iteration6'],comb6['Loss6'])\n",
        "plt.title('Loss Vs Iteration Curve')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-wghAslhGMa"
      },
      "source": [
        "# Combination-7\n",
        "iteration=15000, epoch=82, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=4, activations=SELU, Loss function=CrossEntropyLoss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBb2NiKRhMmY"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 200\n",
        "num_iters = 15000\n",
        "num_hidden = 200\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jew7T_5ChVw8",
        "outputId": "554d507d-f412-4b0e-b51c-9f0bfa360e09"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZopFcmfXhbqN",
        "outputId": "cadac55d-85c6-484f-8fc5-acb6a41e5954"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 20\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:98\n",
            "Test dataloader:25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDt76L2_hgdl"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.SELU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.SELU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.SELU()\n",
        " \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.SELU()\n",
        "\n",
        "       \n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        #self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        #self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### 7th hidden layer: 200 --> 200\n",
        "        #self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #self.relu_7 = nn.ReLU()\n",
        "\n",
        "        ### 8th hidden layer: 200 --> 200\n",
        "        #self.linear_8 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #self.relu_8 = nn.ReLU()'''\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        #out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        #out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #out = self.relu_6(out)\n",
        "\n",
        "        ### 7th hidden layer\n",
        "        #out  = self.linear_7(out)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #out = self.relu_7(out)\n",
        "\n",
        "        ### 8th hidden layer\n",
        "        #out  = self.linear_8(out)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #out = self.relu_8(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEvcLE30hopr",
        "outputId": "d28b73f7-3a54-4057-bc16-d3c86f4cb455"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): SELU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): SELU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): SELU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): SELU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh64AlgchtLi"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY_QmCkOhx5G",
        "outputId": "13fb7b34-4067-4418-813e-4783bc0e6fe2"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Iteration: 500. Loss: 1.8637001514434814. Accuracy: 31.30273718872196\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Iteration: 1000. Loss: 1.8975725173950195. Accuracy: 37.682650751183374\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "Iteration: 1500. Loss: 1.5018588304519653. Accuracy: 46.840913768265075\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "Iteration: 2000. Loss: 1.3317298889160156. Accuracy: 53.159086231734925\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "Iteration: 2500. Loss: 0.9394384026527405. Accuracy: 59.88886602181519\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "Iteration: 3000. Loss: 0.8362199664115906. Accuracy: 65.93949372298827\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "Iteration: 3500. Loss: 0.6445252299308777. Accuracy: 67.5653426630994\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "Iteration: 4000. Loss: 0.877051591873169. Accuracy: 62.07038485285038\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "Iteration: 4500. Loss: 0.893920361995697. Accuracy: 65.46614529738629\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "Iteration: 5000. Loss: 0.5110571384429932. Accuracy: 73.30726486931468\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "Iteration: 5500. Loss: 0.41845202445983887. Accuracy: 71.70199629553406\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "Iteration: 6000. Loss: 0.6463388204574585. Accuracy: 72.79275571105165\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "Iteration: 6500. Loss: 0.3052468001842499. Accuracy: 76.04445359127392\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "Iteration: 7000. Loss: 0.5892701148986816. Accuracy: 75.18007820539205\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "Iteration: 7500. Loss: 0.3990875482559204. Accuracy: 73.01913974068738\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "Iteration: 8000. Loss: 0.2906687259674072. Accuracy: 74.76847087878164\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "Iteration: 8500. Loss: 0.4239502251148224. Accuracy: 75.13891747273101\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "Iteration: 9000. Loss: 0.43275025486946106. Accuracy: 68.656102078617\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "Iteration: 9500. Loss: 0.19316385686397552. Accuracy: 77.58798106606298\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "Iteration: 10000. Loss: 0.6600372195243835. Accuracy: 63.98435892158881\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "Iteration: 10500. Loss: 0.18975919485092163. Accuracy: 77.89668656102079\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "Iteration: 11000. Loss: 0.13333240151405334. Accuracy: 74.5215064828154\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "Iteration: 11500. Loss: 0.17956937849521637. Accuracy: 76.64128421485903\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "Iteration: 12000. Loss: 0.09171736985445023. Accuracy: 77.0117308088084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3I-RWS6ES8G"
      },
      "source": [
        "#Combination-8\n",
        "iteration=10000, epoch=82, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=4, activations=SELU, Loss function=CrossEntropyLoss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_8KlgiQEbCI"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 200\n",
        "num_iters = 10000\n",
        "num_hidden = 200\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6e31T3_EeUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafbb6e3-2d7d-47c9-9a00-123e4bb0931e"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIJ8XTWMEhmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef826ead-e955-44ee-c03f-ed2216a1afce"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 20\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:98\n",
            "Test dataloader:25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC3KC5oTEk69"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.SELU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.SELU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.SELU()\n",
        " \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.SELU()\n",
        "\n",
        "       \n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        #self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        #self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### 7th hidden layer: 200 --> 200\n",
        "        #self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #self.relu_7 = nn.ReLU()\n",
        "\n",
        "        ### 8th hidden layer: 200 --> 200\n",
        "        #self.linear_8 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #self.relu_8 = nn.ReLU()'''\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        #out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        #out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #out = self.relu_6(out)\n",
        "\n",
        "        ### 7th hidden layer\n",
        "        #out  = self.linear_7(out)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #out = self.relu_7(out)\n",
        "\n",
        "        ### 8th hidden layer\n",
        "        #out  = self.linear_8(out)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #out = self.relu_8(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCzYD4JvErGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a26cfb7-7557-4534-cacb-eb3e75de59e7"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): SELU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): SELU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): SELU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): SELU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaqiVsomEuo8"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj32F4fMEyDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3e6b7c-d38d-41ce-f131-64cbf3a46b4b"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Iteration: 500. Loss: 1.9150986671447754. Accuracy: 23.4821979831241\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Iteration: 1000. Loss: 1.6970553398132324. Accuracy: 42.95122453179667\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "Iteration: 1500. Loss: 1.4622122049331665. Accuracy: 50.463058242436716\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "Iteration: 2000. Loss: 1.176350474357605. Accuracy: 54.99073883515126\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "Iteration: 2500. Loss: 0.9785363674163818. Accuracy: 59.97118748713727\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "Iteration: 3000. Loss: 0.8151207566261292. Accuracy: 65.30150236674213\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "Iteration: 3500. Loss: 0.7794908285140991. Accuracy: 69.66454002881251\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "Iteration: 4000. Loss: 0.680691123008728. Accuracy: 71.14632640461001\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "Iteration: 4500. Loss: 0.5687867403030396. Accuracy: 73.92467585923029\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "Iteration: 5000. Loss: 0.4916155934333801. Accuracy: 68.77958427660012\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "Iteration: 5500. Loss: 0.42442309856414795. Accuracy: 73.3278452356452\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "Iteration: 6000. Loss: 0.4347649812698364. Accuracy: 75.85923029429924\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "Iteration: 6500. Loss: 0.6630135178565979. Accuracy: 75.18007820539205\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "Iteration: 7000. Loss: 0.4114518463611603. Accuracy: 77.62914179872402\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "Iteration: 7500. Loss: 0.25005432963371277. Accuracy: 79.48137476847089\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "Iteration: 8000. Loss: 0.5071713328361511. Accuracy: 76.60012348219799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU6yIsdjLlwv"
      },
      "source": [
        "# Combination-9\n",
        "iteration=10000, epoch=82, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 250, Layer=4, activations=SELU, Loss function=CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A7sKd0XLpMp"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 200\n",
        "num_iters = 10000\n",
        "num_hidden = 250\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPZnvXF6L0Kp",
        "outputId": "cdbedb4a-c1d5-4f72-8207-687fac5693e4"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAk2oL41L63O",
        "outputId": "1df75526-f692-49a6-da45-bc3123d9f05c"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 20\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:98\n",
            "Test dataloader:25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EchdKo1tMBR8"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.SELU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.SELU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.SELU()\n",
        " \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.SELU()\n",
        "\n",
        "       \n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        #self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        #self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### 7th hidden layer: 200 --> 200\n",
        "        #self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #self.relu_7 = nn.ReLU()\n",
        "\n",
        "        ### 8th hidden layer: 200 --> 200\n",
        "        #self.linear_8 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #self.relu_8 = nn.ReLU()'''\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        #out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        #out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #out = self.relu_6(out)\n",
        "\n",
        "        ### 7th hidden layer\n",
        "        #out  = self.linear_7(out)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #out = self.relu_7(out)\n",
        "\n",
        "        ### 8th hidden layer\n",
        "        #out  = self.linear_8(out)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #out = self.relu_8(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9QpiqpaMJkt",
        "outputId": "6a09ed9b-994e-475b-c6e6-46bcad0fdc14"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=250, bias=True)\n",
              "  (relu_1): SELU()\n",
              "  (linear_2): Linear(in_features=250, out_features=250, bias=True)\n",
              "  (relu_2): SELU()\n",
              "  (linear_3): Linear(in_features=250, out_features=250, bias=True)\n",
              "  (relu_3): SELU()\n",
              "  (linear_4): Linear(in_features=250, out_features=250, bias=True)\n",
              "  (relu_4): SELU()\n",
              "  (linear_out): Linear(in_features=250, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwFFzJC8MPfA"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Cr5affMUvw",
        "outputId": "66e2ccce-4111-47ee-e8f5-c80cf7512d51"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Iteration: 500. Loss: 1.9172122478485107. Accuracy: 29.82095081292447\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Iteration: 1000. Loss: 1.7936608791351318. Accuracy: 42.45729573986417\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "Iteration: 1500. Loss: 1.5734988451004028. Accuracy: 47.478905124511215\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "Iteration: 2000. Loss: 1.0095208883285522. Accuracy: 56.32846264663511\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "Iteration: 2500. Loss: 1.1114596128463745. Accuracy: 61.96748302119778\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "Iteration: 3000. Loss: 1.011440396308899. Accuracy: 57.64560609178844\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "Iteration: 3500. Loss: 0.8413827419281006. Accuracy: 66.90677094052275\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "Iteration: 4000. Loss: 0.807898759841919. Accuracy: 70.87878164231323\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "Iteration: 4500. Loss: 0.6377882957458496. Accuracy: 72.60753241407697\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "Iteration: 5000. Loss: 0.7013267278671265. Accuracy: 71.45503189956781\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "Iteration: 5500. Loss: 0.47322365641593933. Accuracy: 74.87137271043424\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "Iteration: 6000. Loss: 0.5446150898933411. Accuracy: 63.90203745626672\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "Iteration: 6500. Loss: 0.39106065034866333. Accuracy: 76.57954311586747\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "Iteration: 7000. Loss: 0.3493228852748871. Accuracy: 71.33154970158469\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "Iteration: 7500. Loss: 0.3289399743080139. Accuracy: 72.52521094875489\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "Iteration: 8000. Loss: 0.2973024249076843. Accuracy: 76.33257871990122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUL0I8oo4vKg"
      },
      "source": [
        "#Combination-10\n",
        "iteration=10000, epoch=82, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=4, activations=GELU, Loss function=CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-AorPw-45F6"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 200\n",
        "num_iters = 10000\n",
        "num_hidden = 200\n",
        "input_dim = 180*180 # num_features \n",
        "output_dim = 10\n",
        "save_model = True\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrQCKGl-4_FX",
        "outputId": "e1cd7d37-46a5-43ab-b7b4-2c0b717b7f4d"
      },
      "source": [
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1B-X4ir5FH_",
        "outputId": "6813e306-1707-4d0a-fd25-9f9cbe328d0a"
      },
      "source": [
        "#batch size\n",
        "#batch_size = 20\n",
        "\n",
        "# split data 20% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:98\n",
            "Test dataloader:25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdIhT0JW5MXg"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.GELU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.GELU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.GELU()\n",
        " \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.GELU()\n",
        "\n",
        "       \n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        #self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        #self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### 7th hidden layer: 200 --> 200\n",
        "        #self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #self.relu_7 = nn.ReLU()\n",
        "\n",
        "        ### 8th hidden layer: 200 --> 200\n",
        "        #self.linear_8 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #self.relu_8 = nn.ReLU()'''\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        #out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        #out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #out = self.relu_6(out)\n",
        "\n",
        "        ### 7th hidden layer\n",
        "        #out  = self.linear_7(out)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #out = self.relu_7(out)\n",
        "\n",
        "        ### 8th hidden layer\n",
        "        #out  = self.linear_8(out)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #out = self.relu_8(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH8Ltgri5Ufc",
        "outputId": "226d8137-6af1-4d9b-b660-db593272f007"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=32400, out_features=200, bias=True)\n",
              "  (relu_1): GELU()\n",
              "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_2): GELU()\n",
              "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_3): GELU()\n",
              "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (relu_4): GELU()\n",
              "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE0EctQ95ZvI"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3NKOd8H5e4g",
        "outputId": "44d6e683-1af8-4fd4-eec4-5747cdbc69eb"
      },
      "source": [
        "'''\n",
        "TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Iteration: 500. Loss: 2.1001312732696533. Accuracy: 21.012554023461618\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Iteration: 1000. Loss: 1.971979022026062. Accuracy: 30.067915208890717\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "Iteration: 1500. Loss: 1.8863804340362549. Accuracy: 32.57871990121424\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "Iteration: 2000. Loss: 1.8646554946899414. Accuracy: 33.340193455443504\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "Iteration: 2500. Loss: 1.772462010383606. Accuracy: 35.27474789051245\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "Iteration: 3000. Loss: 2.036921262741089. Accuracy: 35.85099814776703\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "Iteration: 3500. Loss: 1.7558461427688599. Accuracy: 35.37764972216505\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "Iteration: 4000. Loss: 1.85085129737854. Accuracy: 32.99032722782466\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "Iteration: 4500. Loss: 1.661268711090088. Accuracy: 37.92961514714962\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "Iteration: 5000. Loss: 1.9628487825393677. Accuracy: 27.865816011525006\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "Iteration: 5500. Loss: 1.750828742980957. Accuracy: 36.53015023667421\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "Iteration: 6000. Loss: 1.6680352687835693. Accuracy: 33.87528298003704\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "Iteration: 6500. Loss: 1.613863468170166. Accuracy: 35.39823008849557\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "Iteration: 7000. Loss: 1.6607460975646973. Accuracy: 39.32908005762503\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "Iteration: 7500. Loss: 1.6466615200042725. Accuracy: 37.08582012759827\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "Iteration: 8000. Loss: 1.8190276622772217. Accuracy: 36.73595389997942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjmiC0eRgAbk"
      },
      "source": [
        "# Performance Testing with another Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8xFmJCQijq0"
      },
      "source": [
        "# Experiment1-Combination 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE3BrSbaip37",
        "outputId": "012ee81f-1e58-4ffb-b28f-8e4d40d07503"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 20\n",
        "num_iters = 20000\n",
        "input_dim = 28*28\n",
        "num_hidden = 200\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False) \n",
        "\n",
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.ReLU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.ReLU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.ReLU()\n",
        "\n",
        "        \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.ReLU()\n",
        "\n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                           num_classes = output_dim,\n",
        "                           num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 28*28).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 1.0349723100662231. Accuracy: 84.06\n",
            "Iteration: 1000. Loss: 0.3094385266304016. Accuracy: 89.28\n",
            "Iteration: 1500. Loss: 0.4750904142856598. Accuracy: 88.62\n",
            "Iteration: 2000. Loss: 0.3435335159301758. Accuracy: 81.03\n",
            "Iteration: 2500. Loss: 0.24113428592681885. Accuracy: 90.9\n",
            "Iteration: 3000. Loss: 0.23745779693126678. Accuracy: 91.07\n",
            "Iteration: 3500. Loss: 0.6005517244338989. Accuracy: 89.65\n",
            "Iteration: 4000. Loss: 0.3076748549938202. Accuracy: 91.1\n",
            "Iteration: 4500. Loss: 0.41867780685424805. Accuracy: 87.56\n",
            "Iteration: 5000. Loss: 0.7964999675750732. Accuracy: 79.1\n",
            "Iteration: 5500. Loss: 0.6939133405685425. Accuracy: 76.76\n",
            "Iteration: 6000. Loss: 0.39346760511398315. Accuracy: 87.76\n",
            "Iteration: 6500. Loss: 0.25464463233947754. Accuracy: 89.38\n",
            "Iteration: 7000. Loss: 0.4782261848449707. Accuracy: 87.39\n",
            "Iteration: 7500. Loss: 0.20010867714881897. Accuracy: 89.66\n",
            "Iteration: 8000. Loss: 0.47478875517845154. Accuracy: 86.91\n",
            "Iteration: 8500. Loss: 0.20659597218036652. Accuracy: 90.52\n",
            "Iteration: 9000. Loss: 0.03155911713838577. Accuracy: 89.95\n",
            "Iteration: 9500. Loss: 0.6697450876235962. Accuracy: 92.17\n",
            "Iteration: 10000. Loss: 0.8699396848678589. Accuracy: 78.61\n",
            "Iteration: 10500. Loss: 0.657422661781311. Accuracy: 86.14\n",
            "Iteration: 11000. Loss: 0.4187160134315491. Accuracy: 67.81\n",
            "Iteration: 11500. Loss: 0.17535710334777832. Accuracy: 79.46\n",
            "Iteration: 12000. Loss: 0.7310940623283386. Accuracy: 79.19\n",
            "Iteration: 12500. Loss: 0.4071020483970642. Accuracy: 77.84\n",
            "Iteration: 13000. Loss: 0.8195520639419556. Accuracy: 82.18\n",
            "Iteration: 13500. Loss: 1.5266315937042236. Accuracy: 74.79\n",
            "Iteration: 14000. Loss: 0.400900661945343. Accuracy: 73.48\n",
            "Iteration: 14500. Loss: 1.1020221710205078. Accuracy: 81.32\n",
            "Iteration: 15000. Loss: 1.856793761253357. Accuracy: 60.06\n",
            "Iteration: 15500. Loss: 5.326106071472168. Accuracy: 64.68\n",
            "Iteration: 16000. Loss: 0.6460127830505371. Accuracy: 73.9\n",
            "Iteration: 16500. Loss: 1.002711296081543. Accuracy: 75.89\n",
            "Iteration: 17000. Loss: 0.9870090484619141. Accuracy: 62.99\n",
            "Iteration: 17500. Loss: 1.1636487245559692. Accuracy: 75.2\n",
            "Iteration: 18000. Loss: 0.7051276564598083. Accuracy: 74.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8K5xgwxgId-"
      },
      "source": [
        "#Experiment 2 For best model-Combination 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8d502e7eb6ca4069bd27062b74b331dd",
            "dfa9928cc22244deb2bc9fb49d4e987e",
            "49e1b143c3a54265993acf8ab3d18410",
            "38f0e88647e942d79e30f60eef63fb58",
            "8c696c736ff6403f8fdea2651ba92237",
            "13a0b2f2c4284b198736384021a22fdf",
            "f32fd84fbb0e4bce922ff7261546e490",
            "0bfe9836ef4d491fa3096c993f716199",
            "9d66e923a1794fe7bc980471e7693531",
            "d9ae84da2d80461ca310e9974159a45c",
            "e26f8f9127314038a10e9a179692f678",
            "47844d3b80644b2dae20e2010948a5ef",
            "f2925d88ecc54d79a1024ee5082b1649",
            "f58ac42abdb246ac8c0d67ef98433e35",
            "3cdb21f4ec3a4474943ed4e0f41c1718",
            "a1d08a47af1342928d5da6de3779b3bc",
            "5f9fac10911141e5a4ad95087975a8f3",
            "3eff9abe11fd49719a494c0878f2aeeb",
            "66cd0ae1c693464b834b4d3e1bdaf515",
            "54d7cfc7d3d446fcadc1ff3a31c88d4c",
            "c835b5ebef03480dbea0c8520cc4fc1b",
            "c211dff27db34d01b56a507d984e5e4e",
            "b86a8364470d4139a49a32b34b4dd286",
            "3a352e8542a74b73b6d024aba70d2550",
            "e2699895199541d6a749d2f2afaf6840",
            "f52bde03a1c4472eb724fb0e4953fde4",
            "cfe7dfee2f6c41e99c70ad483c2a56d2",
            "f81e1a25078a4be29a0203344bcb8528",
            "cba37857a632416eb6050ceea00bb3cc",
            "1288fddb9d804efd88ff40de012574e1",
            "4cbb9c2e7a0040aabc1a116bbf3d5e06",
            "1b76d89644ae40cbbd98aff08230ec3b",
            "bc8233d5e7124c64a3cd58cf7515292e",
            "f214691a272e4ab68ffe129e790c2f71",
            "cd09e4d94079481484e65c451c25c76a",
            "8aa66404af5647f4a3687e831ee5956e",
            "967420326e954ecab44016beb8f824e7",
            "893c8d81c5b9420eb82cc964bc474fed",
            "ab57363afa2f47e38a51d43256fe5406",
            "380e25e9c60e4788be7730704bb8b3d0",
            "234faa2d11c240cba498dd9adc56dc24",
            "5e65fff091a04d4bb1badb0a08b55114",
            "5cc753dbee744fa389353fc71e8e2a44",
            "f4ae763339cf4a05bbbb47fc920674cd"
          ]
        },
        "id": "WbxNuP6ygG9d",
        "outputId": "692d2608-7d77-49d9-e666-16dc4e00254a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 200\n",
        "num_iters = 20000\n",
        "input_dim = 28*28 # num_features \n",
        "num_hidden = 200\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False) \n",
        "\n",
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 32400 --> 200\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.relu_1 = nn.SELU()\n",
        "\n",
        "        ### 2nd hidden layer: 200 --> 200\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.relu_2 = nn.SELU()\n",
        "\n",
        "        ### 3rd hidden layer: 200 --> 200\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.relu_3 = nn.SELU()\n",
        " \n",
        "        ### 4th hidden layer: 200 --> 200\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.relu_4 = nn.SELU()\n",
        "\n",
        "       \n",
        "        ### 5th hidden layer: 200 --> 200\n",
        "        #self.linear_5 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #self.relu_5 = nn.ReLU()\n",
        "\n",
        "        ### 6th hidden layer: 200 --> 200\n",
        "        #self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #self.relu_6 = nn.ReLU()\n",
        "\n",
        "\n",
        "        ### 7th hidden layer: 200 --> 200\n",
        "        #self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #self.relu_7 = nn.ReLU()\n",
        "\n",
        "        ### 8th hidden layer: 200 --> 200\n",
        "        #self.linear_8 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #self.relu_8 = nn.ReLU()'''\n",
        "\n",
        "\n",
        "        ### Output layer: 200 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        "\n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        "\n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        out = self.relu_4(out)\n",
        "\n",
        "        ### 5thd hidden layer\n",
        "        #out  = self.linear_5(out)\n",
        "        ### Non-linearity in 5th hidden layer\n",
        "        #out = self.relu_5(out)\n",
        "\n",
        "        ### 6th hidden layer\n",
        "        #out  = self.linear_6(out)\n",
        "        ### Non-linearity in 6th hidden layer\n",
        "        #out = self.relu_6(out)\n",
        "\n",
        "        ### 7th hidden layer\n",
        "        #out  = self.linear_7(out)\n",
        "        ### Non-linearity in 7th hidden layer\n",
        "        #out = self.relu_7(out)\n",
        "\n",
        "        ### 8th hidden layer\n",
        "        #out  = self.linear_8(out)\n",
        "        ### Non-linearity in 8th hidden layer\n",
        "        #out = self.relu_8(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        "\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                           num_classes = output_dim,\n",
        "                           num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 28*28).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d502e7eb6ca4069bd27062b74b331dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47844d3b80644b2dae20e2010948a5ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b86a8364470d4139a49a32b34b4dd286",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f214691a272e4ab68ffe129e790c2f71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 0.11320113390684128. Accuracy: 94.21\n",
            "Iteration: 1000. Loss: 0.13235239684581757. Accuracy: 95.74\n",
            "Iteration: 1500. Loss: 0.0425771102309227. Accuracy: 96.53\n",
            "Iteration: 2000. Loss: 0.06174154579639435. Accuracy: 97.17\n",
            "Iteration: 2500. Loss: 0.053917866200208664. Accuracy: 97.11\n",
            "Iteration: 3000. Loss: 0.05843278020620346. Accuracy: 97.41\n",
            "Iteration: 3500. Loss: 0.008049875497817993. Accuracy: 97.55\n",
            "Iteration: 4000. Loss: 0.033867932856082916. Accuracy: 97.75\n",
            "Iteration: 4500. Loss: 0.0323578417301178. Accuracy: 97.53\n",
            "Iteration: 5000. Loss: 0.02022767812013626. Accuracy: 97.78\n",
            "Iteration: 5500. Loss: 0.007144459988921881. Accuracy: 97.89\n",
            "Iteration: 6000. Loss: 0.06417857855558395. Accuracy: 97.78\n",
            "Iteration: 6500. Loss: 0.046498361974954605. Accuracy: 97.61\n",
            "Iteration: 7000. Loss: 0.003038631984964013. Accuracy: 97.98\n",
            "Iteration: 7500. Loss: 0.01417429931461811. Accuracy: 97.96\n",
            "Iteration: 8000. Loss: 0.020506955683231354. Accuracy: 97.68\n",
            "Iteration: 8500. Loss: 0.011634545400738716. Accuracy: 98.02\n",
            "Iteration: 9000. Loss: 0.017086613923311234. Accuracy: 97.75\n",
            "Iteration: 9500. Loss: 0.0029033226892352104. Accuracy: 97.76\n",
            "Iteration: 10000. Loss: 0.032336995005607605. Accuracy: 98.01\n",
            "Iteration: 10500. Loss: 0.003414545673877001. Accuracy: 97.69\n",
            "Iteration: 11000. Loss: 0.0010431930422782898. Accuracy: 98.07\n",
            "Iteration: 11500. Loss: 0.0019008226227015257. Accuracy: 98.23\n",
            "Iteration: 12000. Loss: 0.00752218859270215. Accuracy: 97.67\n",
            "Iteration: 12500. Loss: 0.016116295009851456. Accuracy: 97.94\n",
            "Iteration: 13000. Loss: 0.0008405324188061059. Accuracy: 97.94\n",
            "Iteration: 13500. Loss: 0.015968015417456627. Accuracy: 97.99\n",
            "Iteration: 14000. Loss: 0.0613706149160862. Accuracy: 97.88\n",
            "Iteration: 14500. Loss: 0.007717065047472715. Accuracy: 98.12\n",
            "Iteration: 15000. Loss: 0.07477280497550964. Accuracy: 97.72\n",
            "Iteration: 15500. Loss: 0.01875152438879013. Accuracy: 98.01\n",
            "Iteration: 16000. Loss: 0.00544356694445014. Accuracy: 98.18\n",
            "Iteration: 16500. Loss: 0.00010424643551232293. Accuracy: 98.28\n",
            "Iteration: 17000. Loss: 0.019356276839971542. Accuracy: 98.13\n",
            "Iteration: 17500. Loss: 9.456779662286863e-05. Accuracy: 97.96\n",
            "Iteration: 18000. Loss: 0.000128005092847161. Accuracy: 98.01\n",
            "Iteration: 18500. Loss: 0.03723379224538803. Accuracy: 97.89\n",
            "Iteration: 19000. Loss: 0.009812318719923496. Accuracy: 97.93\n",
            "Iteration: 19500. Loss: 0.016852037981152534. Accuracy: 97.78\n"
          ]
        }
      ]
    }
  ]
}